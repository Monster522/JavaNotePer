## 面试常见问题

### 1.Rocket优缺点

**RocketMQ优点**：

- 单机吞吐量：十万级

- 可用性：非常高，分布式架构

- 消息可靠性：经过参数优化配置，消息可以做到0丢失

- 功能支持：MQ功能较为完善，还是分布式的，扩展性好

- **支持10亿级别的消息堆积**，不会因为堆积导致性能下降

- 源码是java，我们可以自己阅读源码，定制自己公司的MQ，可以掌控 

- 天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况

- RoketMQ在稳定性上可能更值得信赖，这些业务场景在阿里双11已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择RocketMQ

**RocketMQ缺点**：

-  支持的客户端语言不多，目前是java及c++，其中c++不成熟

- 社区活跃度不是特别活跃那种

- 没有在mq核心中去实现**JMS**等接口，有些系统要迁移需要修改大量代码 

### 2.消息去重

- 去重原则

  使用业务端逻辑保持幂等性

- **幂等性**
  1. 就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用，数据库的结果都是唯一的，不可变的。
  2. 只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样，需要业务端来实现。

- **去重策略**
  1. 保证每条消息都有唯一编号(**比如唯一流水号)**，且保证消息处理成功与去重表的日志同时出现。
  2. 建立一个消息表，拿到这个消息做数据库的insert操作。给这个消息做一个唯一主键（primary key）或者唯一约束，那么就算出现重复消费的情况，就会导致主键冲突，那么就不再处理这条消息。

### 3. 消息重复

- 消息领域有一个对消息投递的`QoS(服务质量)`定义，分为：
  1. 最多一次（At most once）
  2. 至少一次（At least once）
  3. 仅一次（ Exactly once）

- **问题场景**
  1. 几乎所有的MQ产品都做到了**At least once**。那就避免不了消息重复，尤其是在分布式网络环境下。
  2. 比如：网络原因闪断，ACK返回失败等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将该消息分发给其他的消费者。
- **解决方案**
  1. 不同的消息队列发送的确认信息形式不同，例如**RabbitMQ**是发送一个ACK确认消息，**RocketMQ**是返回一个CONSUME_SUCCESS成功标志，**Kafka**实际上有个offset的概念。
  2. RocketMQ没有内置消息去重的解决方案，最新版本是否支持还需确认。

### 4. 消息的可用性

- **持久化消息队列数据(刷盘)**
  1. RocketMQ对消息的刷盘提供了同步和异步的策略，选择**同步刷盘**可以尽最大程度**消息不会丢失**
  2. **同步刷盘**，如果刷盘超时会给返回FLUSH_DISK_TIMEOUT。
  3. **异步刷盘**，不会返回刷盘相关信息。

- **同步复制数据**
  1. 主从同步提供了同步和异步两种模式来进行复制。当然选择同步可以提升可用性，但是消息的发送RT时间会下降10%左右。
- **存储结构**
  1. `RocketMQ`采用的是混合型的存储结构，即为`Broker`单个实例下所有的队列共用一个日志数据文件（即为`CommitLog`）来存储。而`Kafka`采用的是独立型的存储结构，每个队列一个文件。
  2. `RocketMQ`采用混合型存储结构的缺点在于，会存在较多的随机读操作，因此读的效率偏低。同时消费消息需要依赖`ConsumeQueue`，构建该逻辑消费队列需要一定开销。

### 5. RocketMQ 持久化(刷盘)实现

- 定义
  1. Broker在消息的存取时直接操作的是内存(内存映射文件)，这可以提供系统的吞吐量，但是无法避免机器掉电时数据丢失，所以需要持久化到磁盘中。
  2. 刷盘的最终实现，都是使用**NIO**中的`MappedByteBuffer.force()`将映射区的数据写入到磁盘

- 同步刷盘
  1. 如果是同步刷盘，在Broker把消息写到CommitLog映射区后，就会等待写入完成。

- 异步刷盘
  1. 异步而言，只是唤醒对应的线程，不保证执行的时机，流程如图所示。

![](https://javanote.oss-cn-shenzhen.aliyuncs.com/22_消息队列异步持久化流程.png)

### 6. 消息顺序消费

- **问题背景**

  1. 一般都是同个业务场景下不同几个操作的消息同时过去，本身顺序是对的。但是你发出去的时候同时发出去了，消费的时候却乱掉了，这样就有问题了。
  2. 比如在数据库同时对一个Id的数据进行了增、改、删三个操作，但是你消息发过去消费的时候变成了改，删、增，该删除的数据没有删除，这样数据就出错。

  ![](https://javanote.oss-cn-shenzhen.aliyuncs.com/7_消息顺序消费.png)

- **解决方法**

  1. 生产者顺序发送消息。
  2. 消息队列顺序存储消息。
  3. 消费者顺序消费消息。

- **生产者顺序发送消息**

  1. 假设发送消息ABC，确认消息A发送成功后，再继续发送消息B消息C。就可以保证顺序发送消息。

- **消息队列顺序存储消息**

  ![](https://javanote.oss-cn-shenzhen.aliyuncs.com/9_Ro消息队列.png)

  1. 在RocketMQ中，选择队列实现`MessageQueueSelector`，使用Hash取模法，让同一个订单取模后发送到同一个队列中。因为selector保证同一个模的都会投递到同一条Queue，相同的订单号有相同的模，然后发送到相同的Queue。

     如下，订单号2001和3001的消息，会分别顺序存储到各自的队列中。即实现了顺序存储消息。

     ![](https://javanote.oss-cn-shenzhen.aliyuncs.com/10_queue顺序存储.png)

- **消费者顺序消费消息**

  1.  如果是使用`MessageListenerOrderly`则自带此实现，如果是使用`MessageListenerConcurrently`，则需要把线程池改为单线程模式。建议使用后一种方式。
  2. 因为Queue中的消息保证FIFO，即使同一个消费者同时获取到两个Queue，只会出现重复消息而不会出现顺序的问题。

### 6.分布式事务

- **Half Message(半消息)**

  **指暂不能被Consumer消费的消息**。`Producer`已经把消息成功发送到了`Broker`端，但此消息被标记为暂不能投递状态，处于该种状态下的消息称为半消息。需要`Producer`对消息的二次确认后，`Consumer`才能去消费它。

- **消息回查**

  由于网络闪段，生产者应用重启等原因。导致`Producer`端一直没有对`HalfMessage`(半消息)进行二次确认。这是Brock服务器会定时扫描长期处于半消息的消息，会主动询问`Producer`端该消息的最终状态(`Commit或者Rollback`),该消息即为消息回查。

- **消息回查流程**

  ![](https://javanote.oss-cn-shenzhen.aliyuncs.com/23_消息回查.png)

  1. A服务先发送个Half Message给Brock端，消息中携带 B服务 即将要+100元的信息。 
  2. 当A服务知道Half Message发送成功后，那么开始第3步执行本地事务。 
  3. 执行本地事务(会有三种情况1、执行成功。2、执行失败。3、网络等原因导致没有响应) 
  4. 如果本地事务成功，那么Product像Brock服务器发送Commit,这样B服务就可以消费该message。 
  5. 如果本地事务失败，那么Product像Brock服务器发送Rollback,那么就会直接删除上面这条半消息。
  6. 如果因为网络等原因迟迟没有返回失败还是成功，那么会执行RocketMQ的回调接口,来进行事务的回查。

### 7.消息过滤

- **Broker端消息过滤**　　
  在Broker中，按照Consumer的要求做过滤，优点是减少了对于Consumer无用消息的网络传输。缺点是增加了Broker的负担，实现相对复杂。
- **Consumer端消息过滤**
  这种过滤方式可由应用完全自定义实现，但是缺点是很多无用的消息要传输到Consumer端。

### 8. Broker的Buffer问题

- **问题定义**
  
1. Broker的Buffer通常指的是Broker中一个队列的内存Buffer大小，这类Buffer通常大小有限。
  
- **RocketMQ的Buffer**

  1. `RocketMQ`没有内存`Buffer`概念，`RocketMQ`的队列都是持久化磁盘，数据定期清除。

  2. `RocketMQ`同其他MQ有非常显著的区别，`RocketMQ`的内存Buffer抽象成一个无限长度的队列，不管有多少数据进来都能装得下，这个无限是有前提的，`Broker`会定期删除过期的数据。

     例如Broker只保存3天的消息，那么这个**Buffer**虽然长度无限，但是3天前的数据会被从队尾删除。

### 9.回溯消费

- 定义
  1. 是指Consumer已经消费成功的消息，由于业务上的需求需要重新消费，要支持此功能，Broker在向Consumer投递成功消息后，消息仍然需要保留。并且重新消费一般是按照时间维度。
  2. 例如由于Consumer系统故障，恢复后需要重新消费1小时前的数据，那么Broker要提供一种机制，可以按照时间维度来回退消费进度。

- RocketMQ实现

  RocketMQ支持按照时间回溯消费，时间维度精确到毫秒，可以向前回溯，也可以向后回溯。

### 10.消息堆积

- **定义**

  消息中间件的主要功能是异步解耦，还有个重要功能是挡住前端的数据洪峰，保证后端系统的稳定性，这就要求消息中间件具有一定的消息堆积能力

- **消息堆积分以下两种情况**

  1. **消息堆积在内存Buffer**，一旦超过内存Buffer，可以根据一定的丢弃策略来丢弃消息。

     如CORBA Notification规范中描述。适合能容忍丢弃消息的业务，这种情况消息的堆积能力主要在于内存Buffer大小，而且消息堆积后，性能下降不会太大，因为内存中数据多少对于对外提供的访问能力影响有限。

  2. **消息堆积到持久化存储系统中**，例如DB，KV存储，文件记录形式。 

     当消息不能在内存Cache命中时，要不可避免的访问磁盘，会产生大量读IO，读IO的吞吐量直接决定了消息堆积后的访问能力。

- **评估消息堆积能力主要有以下四点**
  
  - 消息能堆积多少条，多少字节？即消息的堆积容量。
  - 消息堆积后，发消息的吞吐量大小，是否会受堆积影响？
  - 消息堆积后，正常消费的Consumer是否会受影响？
  - 消息堆积后，访问堆积在磁盘的消息时，吞吐量有多大？

### 11.定时消息

- **定义**

  是指消息发到`Broker`后，不能立刻被`Consumer`消费，要到特定的时间点或者等待特定的时间后才能被消费。

- **实现**
  1. 如果要支持任意的时间精度，在`Broker`层面，必须要做消息排序，如果再涉及到持久化，那么消息排序要不可避免的产生巨大性能开销。
  2. `RocketMQ`支持定时消息，但是不支持任意时间精度，支持特定的level，例如定时5s，10s，1m等。